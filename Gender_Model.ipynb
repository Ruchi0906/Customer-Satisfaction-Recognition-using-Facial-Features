{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3b3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten , Dense , Dropout , Activation\n",
    "from keras.layers.convolutional import Convolution2D , MaxPooling2D , ZeroPadding2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"C:/Users/Ruchita/Desktop/Project_Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfa585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender_data = pd.read_csv('age_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34539be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120221920654.jpg.chip.jpg</td>\n",
       "      <td>127 100 94 81 77 77 74 99 102 98 128 145 160 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23701</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120134639935.jpg.chip.jpg</td>\n",
       "      <td>23 28 32 35 42 47 68 85 98 103 113 117 130 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182418864.jpg.chip.jpg</td>\n",
       "      <td>59 50 37 40 34 19 30 101 156 170 177 184 187 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170117195405372.jpg.chip.jpg</td>\n",
       "      <td>45 108 120 156 206 197 140 180 191 199 204 207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182052119.jpg.chip.jpg</td>\n",
       "      <td>156 161 160 165 170 173 166 177 183 191 187 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "0        1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1        1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2        1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3        1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4        1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "23700   99          0       1  20170120221920654.jpg.chip.jpg   \n",
       "23701   99          1       1  20170120134639935.jpg.chip.jpg   \n",
       "23702   99          2       1  20170110182418864.jpg.chip.jpg   \n",
       "23703   99          2       1  20170117195405372.jpg.chip.jpg   \n",
       "23704   99          0       1  20170110182052119.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "0      129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1      164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2      67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3      193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4      202 205 209 210 209 209 210 211 212 214 218 21...  \n",
       "...                                                  ...  \n",
       "23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n",
       "23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n",
       "23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n",
       "23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n",
       "23704  156 161 160 165 170 173 166 177 183 191 187 18...  \n",
       "\n",
       "[23705 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_gender_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798985cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = []\n",
    "gender = []\n",
    "\n",
    "for index , row in age_gender_data.iterrows():\n",
    "    k = row['pixels'].split(\" \")\n",
    "    pixels.append(np.array(k ,'float32'))\n",
    "    gender.append(row['gender'])\n",
    "\n",
    "pixels_train = []\n",
    "gender_train = []\n",
    "pixels_test = []\n",
    "gender_test = []\n",
    "\n",
    "pixels_train , pixels_test , gender_train , gender_test = train_test_split(pixels , gender , test_size=0.2 , random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc656b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_train = np.array(pixels_train , 'float32')\n",
    "pixels_test = np.array(pixels_test , 'float32')\n",
    "gender_train = np.array(gender_train , 'float32')\n",
    "gender_test = np.array(gender_test , 'float32')\n",
    "\n",
    "pixels_train = pixels_train.reshape(pixels_train.shape[0] , 48 , 48 , 1)\n",
    "pixels_test = pixels_test.reshape(pixels_test.shape[0] , 48 , 48 , 1)\n",
    "\n",
    "gender_train = to_categorical(gender_train , num_classes = 2)\n",
    "gender_test = to_categorical(gender_test , num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edeeb0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "es=EarlyStopping(patience=10)\n",
    "\n",
    "model.add(Convolution2D(input_shape = (48 , 48 , 1) , filters = 64 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 64 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 128 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 128 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 4096 , activation = 'relu'))\n",
    "model.add(Dense(units = 4096 , activation = 'relu'))\n",
    "model.add(Dense(units = 2 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f85a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'SGD' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fa83f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "238/238 [==============================] - 1150s 5s/step - loss: 0.6621 - accuracy: 0.6088 - val_loss: 0.6094 - val_accuracy: 0.6678\n",
      "Epoch 2/40\n",
      "238/238 [==============================] - 1271s 5s/step - loss: 0.5927 - accuracy: 0.6867 - val_loss: 0.6033 - val_accuracy: 0.6971\n",
      "Epoch 3/40\n",
      "238/238 [==============================] - 1231s 5s/step - loss: 0.4696 - accuracy: 0.7809 - val_loss: 0.9824 - val_accuracy: 0.4756\n",
      "Epoch 4/40\n",
      "238/238 [==============================] - 1154s 5s/step - loss: 0.3934 - accuracy: 0.8219 - val_loss: 0.4440 - val_accuracy: 0.8173\n",
      "Epoch 5/40\n",
      "238/238 [==============================] - 1207s 5s/step - loss: 0.3415 - accuracy: 0.8465 - val_loss: 0.7664 - val_accuracy: 0.6562\n",
      "Epoch 6/40\n",
      "238/238 [==============================] - 1200s 5s/step - loss: 0.3132 - accuracy: 0.8583 - val_loss: 0.9210 - val_accuracy: 0.5191\n",
      "Epoch 7/40\n",
      "238/238 [==============================] - 1203s 5s/step - loss: 0.2950 - accuracy: 0.8713 - val_loss: 0.3348 - val_accuracy: 0.8634\n",
      "Epoch 8/40\n",
      "238/238 [==============================] - 1407s 6s/step - loss: 0.2712 - accuracy: 0.8798 - val_loss: 0.3149 - val_accuracy: 0.8655\n",
      "Epoch 9/40\n",
      "238/238 [==============================] - 1434s 6s/step - loss: 0.2459 - accuracy: 0.8936 - val_loss: 0.4174 - val_accuracy: 0.8086\n",
      "Epoch 10/40\n",
      "238/238 [==============================] - 1420s 6s/step - loss: 0.2316 - accuracy: 0.9020 - val_loss: 0.5575 - val_accuracy: 0.7878\n",
      "Epoch 11/40\n",
      "238/238 [==============================] - 1432s 6s/step - loss: 0.2183 - accuracy: 0.9088 - val_loss: 0.3971 - val_accuracy: 0.8439\n",
      "Epoch 12/40\n",
      "238/238 [==============================] - 4062s 17s/step - loss: 0.1956 - accuracy: 0.9186 - val_loss: 0.8272 - val_accuracy: 0.7385\n",
      "Epoch 13/40\n",
      "238/238 [==============================] - 1295s 5s/step - loss: 0.1909 - accuracy: 0.9197 - val_loss: 0.6264 - val_accuracy: 0.7893\n",
      "Epoch 14/40\n",
      "238/238 [==============================] - 1224s 5s/step - loss: 0.1654 - accuracy: 0.9343 - val_loss: 0.3055 - val_accuracy: 0.8827\n",
      "Epoch 15/40\n",
      "238/238 [==============================] - 1936s 8s/step - loss: 0.1527 - accuracy: 0.9386 - val_loss: 0.2926 - val_accuracy: 0.8901\n",
      "Epoch 16/40\n",
      "238/238 [==============================] - 1180s 5s/step - loss: 0.1383 - accuracy: 0.9464 - val_loss: 0.2933 - val_accuracy: 0.8861\n",
      "Epoch 17/40\n",
      "238/238 [==============================] - 1408s 6s/step - loss: 0.1295 - accuracy: 0.9493 - val_loss: 0.3129 - val_accuracy: 0.8948\n",
      "Epoch 18/40\n",
      "238/238 [==============================] - 1463s 6s/step - loss: 0.1201 - accuracy: 0.9542 - val_loss: 0.4187 - val_accuracy: 0.8616\n",
      "Epoch 19/40\n",
      "238/238 [==============================] - 1371s 6s/step - loss: 0.1058 - accuracy: 0.9605 - val_loss: 0.5855 - val_accuracy: 0.6528\n",
      "Epoch 20/40\n",
      "238/238 [==============================] - 1982s 8s/step - loss: 0.1035 - accuracy: 0.9622 - val_loss: 0.3838 - val_accuracy: 0.8761\n",
      "Epoch 21/40\n",
      "238/238 [==============================] - 1196s 5s/step - loss: 0.0832 - accuracy: 0.9703 - val_loss: 0.9619 - val_accuracy: 0.6699\n",
      "Epoch 22/40\n",
      "238/238 [==============================] - 1144s 5s/step - loss: 0.1262 - accuracy: 0.9530 - val_loss: 0.3487 - val_accuracy: 0.8756\n",
      "Epoch 23/40\n",
      "238/238 [==============================] - 1285s 5s/step - loss: 0.0732 - accuracy: 0.9751 - val_loss: 0.3546 - val_accuracy: 0.8814\n",
      "Epoch 24/40\n",
      "238/238 [==============================] - 1462s 6s/step - loss: 0.0683 - accuracy: 0.9765 - val_loss: 0.3909 - val_accuracy: 0.8869\n",
      "Epoch 25/40\n",
      "238/238 [==============================] - 1473s 6s/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.4012 - val_accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f140e3d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pixels_train , gender_train , batch_size = 64 , epochs = 40 , validation_data = (pixels_test , gender_test),validation_split=0.2,callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f3ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 84s 562ms/step - loss: 0.3607 - accuracy: 0.8933\n",
      "[0.36072733998298645, 0.8932714462280273]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(pixels_test , gender_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "236829ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_gender.json\" , \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    model.save_weights(\"model_gender.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a9ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e14560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
