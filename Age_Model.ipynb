{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0a7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten , Dense , Dropout , Activation\n",
    "from keras.layers.convolutional import Convolution2D , MaxPooling2D , ZeroPadding2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"C:/Users/Ruchita/Desktop/Project_Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e306ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender_data = pd.read_csv('age_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222b5511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120221920654.jpg.chip.jpg</td>\n",
       "      <td>127 100 94 81 77 77 74 99 102 98 128 145 160 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23701</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120134639935.jpg.chip.jpg</td>\n",
       "      <td>23 28 32 35 42 47 68 85 98 103 113 117 130 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182418864.jpg.chip.jpg</td>\n",
       "      <td>59 50 37 40 34 19 30 101 156 170 177 184 187 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170117195405372.jpg.chip.jpg</td>\n",
       "      <td>45 108 120 156 206 197 140 180 191 199 204 207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182052119.jpg.chip.jpg</td>\n",
       "      <td>156 161 160 165 170 173 166 177 183 191 187 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "0        1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1        1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2        1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3        1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4        1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "23700   99          0       1  20170120221920654.jpg.chip.jpg   \n",
       "23701   99          1       1  20170120134639935.jpg.chip.jpg   \n",
       "23702   99          2       1  20170110182418864.jpg.chip.jpg   \n",
       "23703   99          2       1  20170117195405372.jpg.chip.jpg   \n",
       "23704   99          0       1  20170110182052119.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "0      129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1      164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2      67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3      193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4      202 205 209 210 209 209 210 211 212 214 218 21...  \n",
       "...                                                  ...  \n",
       "23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n",
       "23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n",
       "23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n",
       "23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n",
       "23704  156 161 160 165 170 173 166 177 183 191 187 18...  \n",
       "\n",
       "[23705 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_gender_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30bb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = []\n",
    "age = []\n",
    "\n",
    "for index , row in age_gender_data.iterrows():\n",
    "    k = row['pixels'].split(\" \")\n",
    "    pixels.append(np.array(k , 'float32'))\n",
    "    p = row['age']\n",
    "    if(p > 0 and p <= 18):\n",
    "        age.append(0)\n",
    "    elif(p > 18 and p <= 45):\n",
    "        age.append(1)\n",
    "    elif(p > 45 and p <= 60):\n",
    "        age.append(2)\n",
    "    else:\n",
    "        age.append(3)\n",
    "\n",
    "pixels_train = []\n",
    "age_train = []\n",
    "pixels_test = []\n",
    "age_test = []\n",
    "\n",
    "pixels_train , pixels_test , age_train, age_test = train_test_split(pixels , age , test_size=0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e10b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_train = np.array(pixels_train , 'float32')\n",
    "pixels_test = np.array(pixels_test , 'float32')\n",
    "Age_train = np.array(age_train , 'float32')\n",
    "Age_test = np.array(age_test , 'float32')\n",
    "\n",
    "pixels_train = pixels_train.reshape(pixels_train.shape[0] , 48 , 48 , 1)\n",
    "pixels_test = pixels_test.reshape(pixels_test.shape[0] , 48 , 48 , 1)\n",
    "\n",
    "age_train = to_categorical(age_train , num_classes = 4)\n",
    "age_test = to_categorical(age_test , num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829110a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(input_shape = (48 , 48 , 1) , filters = 64 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 64 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 128 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 128 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 256 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 512 , kernel_size = (3 , 3) , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2 , 2) , strides = (2 , 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 4096 , activation = 'relu'))\n",
    "model.add(Dense(units = 4096 , activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 4 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af983bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb4be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "238/238 [==============================] - 686s 3s/step - loss: 1.1272 - accuracy: 0.5750 - val_loss: 2.2902 - val_accuracy: 0.5597\n",
      "Epoch 2/30\n",
      "238/238 [==============================] - 662s 3s/step - loss: 1.0128 - accuracy: 0.6147 - val_loss: 1.4125 - val_accuracy: 0.3414\n",
      "Epoch 3/30\n",
      "238/238 [==============================] - 589s 2s/step - loss: 0.8623 - accuracy: 0.6731 - val_loss: 1.1546 - val_accuracy: 0.5634\n",
      "Epoch 4/30\n",
      "238/238 [==============================] - 584s 2s/step - loss: 0.7842 - accuracy: 0.7029 - val_loss: 0.9927 - val_accuracy: 0.6093\n",
      "Epoch 5/30\n",
      "238/238 [==============================] - 587s 2s/step - loss: 0.7213 - accuracy: 0.7276 - val_loss: 1.4264 - val_accuracy: 0.4516\n",
      "Epoch 6/30\n",
      "238/238 [==============================] - 651s 3s/step - loss: 0.6833 - accuracy: 0.7394 - val_loss: 0.9713 - val_accuracy: 0.6151\n",
      "Epoch 7/30\n",
      "238/238 [==============================] - 617s 3s/step - loss: 0.6389 - accuracy: 0.7535 - val_loss: 1.7040 - val_accuracy: 0.2207\n",
      "Epoch 8/30\n",
      "238/238 [==============================] - 585s 2s/step - loss: 0.6461 - accuracy: 0.7541 - val_loss: 0.8032 - val_accuracy: 0.7155\n",
      "Epoch 9/30\n",
      "238/238 [==============================] - 628s 3s/step - loss: 0.5745 - accuracy: 0.7805 - val_loss: 1.1928 - val_accuracy: 0.4782\n",
      "Epoch 10/30\n",
      "238/238 [==============================] - 652s 3s/step - loss: 0.5455 - accuracy: 0.7878 - val_loss: 0.6119 - val_accuracy: 0.7677\n",
      "Epoch 11/30\n",
      "238/238 [==============================] - 670s 3s/step - loss: 0.5005 - accuracy: 0.8108 - val_loss: 0.8149 - val_accuracy: 0.7147\n",
      "Epoch 12/30\n",
      "238/238 [==============================] - 663s 3s/step - loss: 0.4726 - accuracy: 0.8151 - val_loss: 0.7014 - val_accuracy: 0.7590\n",
      "Epoch 13/30\n",
      "238/238 [==============================] - 661s 3s/step - loss: 0.4319 - accuracy: 0.8319 - val_loss: 3.2251 - val_accuracy: 0.1832\n",
      "Epoch 14/30\n",
      "238/238 [==============================] - 664s 3s/step - loss: 0.5865 - accuracy: 0.7762 - val_loss: 0.9997 - val_accuracy: 0.6971\n",
      "Epoch 15/30\n",
      "238/238 [==============================] - 1719s 7s/step - loss: 0.4045 - accuracy: 0.8412 - val_loss: 0.7531 - val_accuracy: 0.7519\n",
      "Epoch 16/30\n",
      "238/238 [==============================] - 584s 2s/step - loss: 0.3690 - accuracy: 0.8566 - val_loss: 1.6733 - val_accuracy: 0.2610\n",
      "Epoch 17/30\n",
      "238/238 [==============================] - 586s 2s/step - loss: 0.3686 - accuracy: 0.8553 - val_loss: 3.1230 - val_accuracy: 0.1896\n",
      "Epoch 18/30\n",
      "238/238 [==============================] - 610s 3s/step - loss: 0.4993 - accuracy: 0.8067 - val_loss: 0.7064 - val_accuracy: 0.7627\n",
      "Epoch 19/30\n",
      "238/238 [==============================] - 593s 2s/step - loss: 0.2957 - accuracy: 0.8861 - val_loss: 0.8755 - val_accuracy: 0.7672\n",
      "Epoch 20/30\n",
      "238/238 [==============================] - 979s 4s/step - loss: 0.2533 - accuracy: 0.9022 - val_loss: 0.6823 - val_accuracy: 0.7675\n",
      "Epoch 21/30\n",
      "238/238 [==============================] - 683s 3s/step - loss: 0.2193 - accuracy: 0.9166 - val_loss: 2.3767 - val_accuracy: 0.4021\n",
      "Epoch 22/30\n",
      "238/238 [==============================] - 599s 3s/step - loss: 0.2650 - accuracy: 0.9032 - val_loss: 1.3348 - val_accuracy: 0.6633\n",
      "Epoch 23/30\n",
      "238/238 [==============================] - 588s 2s/step - loss: 0.1740 - accuracy: 0.9345 - val_loss: 2.5796 - val_accuracy: 0.4105\n",
      "Epoch 24/30\n",
      "238/238 [==============================] - 617s 3s/step - loss: 0.2445 - accuracy: 0.9078 - val_loss: 0.8157 - val_accuracy: 0.7864\n",
      "Epoch 25/30\n",
      "238/238 [==============================] - 609s 3s/step - loss: 0.1312 - accuracy: 0.9527 - val_loss: 0.9510 - val_accuracy: 0.7780\n",
      "Epoch 26/30\n",
      "238/238 [==============================] - 598s 3s/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 3.2521 - val_accuracy: 0.5874\n",
      "Epoch 27/30\n",
      "238/238 [==============================] - 593s 2s/step - loss: 0.2532 - accuracy: 0.9100 - val_loss: 0.9648 - val_accuracy: 0.7627\n",
      "Epoch 28/30\n",
      "238/238 [==============================] - 594s 2s/step - loss: 0.1071 - accuracy: 0.9616 - val_loss: 1.8911 - val_accuracy: 0.7190\n",
      "Epoch 29/30\n",
      "238/238 [==============================] - 610s 3s/step - loss: 0.1206 - accuracy: 0.9595 - val_loss: 0.8944 - val_accuracy: 0.7770\n",
      "Epoch 30/30\n",
      "238/238 [==============================] - 615s 3s/step - loss: 0.0624 - accuracy: 0.9808 - val_loss: 1.0070 - val_accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bc9a26de20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(pixels_train , age_train , batch_size = 64 , epochs = 30 , verbose = 1 , validation_data = (pixels_test , age_test) , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13da2f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 33s 219ms/step - loss: 0.9590 - accuracy: 0.7891\n",
      "[0.9589807987213135, 0.7890740633010864]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(pixels_test , age_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3098f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_age.json\" , \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    model.save_weights(\"model_age.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1436771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
